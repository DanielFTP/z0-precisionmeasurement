{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minute-collaboration",
   "metadata": {},
   "source": [
    "# Exercise 3: Measurement of the total production cross sections\n",
    "\n",
    "For **each** of the seven centre-of-mass energies:\n",
    "* Determine the number of events in the handronic channel *and* in the three leptonic channels\n",
    "* Substract the background and correct for selection efficiencies accordingly\n",
    "* Then, calculate the differnetial cross sections for the hadronic *and* the leptnic channels\n",
    "* Add the radiation corrections from The table given below. **Don't forget to take the uncertainties (errors) into account!**\n",
    "\n",
    "| $\\sqrt{s}$   \\[GeV\\]| Correction hadronic channel    \\[nb\\] |  Correction leptonic channel   \\[nb\\]|\n",
    "| --- | --- | --- |\n",
    "| 88.47 | +2.0  | +0.09 |\n",
    "| 89.46 | +4.3  | +0.20 |\n",
    "| 90.22 | +7.7  | +0.36 |\n",
    "| 91.22 | +10.8 | +0.52 |\n",
    "| 91.97 | +4.7  | +0.22 |\n",
    "| 92.96 | -0.2  | -0.01 |\n",
    "| 93.76 | -1.6  | -0.08 |\n",
    "\n",
    "Feel free to access these values using the dictionary 'xs_corrections' given below.\n",
    "* Once the total cross section for all four decay channels at all seven energies have been measured, fit a **Breit-Wigner distribution** to measure the $Z$ boson mass ($m_Z$) and the resonance width ($\\Gamma_Z$) and the peak cross section s of the resonance for the hadronic and the leptonic channels. Again, **propagate the uncertainties carefully**.\n",
    "* Compare your results to the OPAL cross section s and the theoretical predictions. How many degrees of freedom does the fit have? How can you udge if the model is compatible with the measured data? Calculate the  **confidence levels**.\n",
    "* Calculate the partial widths for all channels from the measured cross sections on the peak. Which is the best partial width to start with? Compare them with the theoretical predictions and the values that you have calculated in the beginning.\n",
    "* Determine from your results the **number of generations of light neutrinos**. Which assumptions are necessary?\n",
    "* Discuss in detail the systematic uncertainties in the whole procedure of the analysis. Which assumptions were necessary?\n",
    "\n",
    "These are some **references** that might be interesting to look up:\n",
    "* Particle Data Book: https://pdg.lbl.gov/2020/download/Prog.Theor.Exp.Phys.2020.083C01.pdf\n",
    "** Resonances: https://pdg.lbl.gov/2017/reviews/rpp2017-rev-resonances.pdf\n",
    "* Precision Electroweak Measurements on the Z Resonance (Combination LEP): https://arxiv.org/abs/hep-ex/0509008\n",
    "* Measurement of the $Z^0$ mass and width with the OPAL detector at LEP: https://doi.org/10.1016/0370-2693(89)90705-3\n",
    "* Measurement of the $Z^0$ line shape parameters and the electroweak couplings of charged leptons: https://inspirehep.net/literature/315269\n",
    "* The OPAL Collaboration, *Precise Determination of the $Z$ Resonance Parameters at LEP: \"Zedometry\"*: https://arxiv.org/abs/hep-ex/0012018\n",
    "* Fitting a Breit-Wigner curve using uproot: https://masonproffitt.github.io/uproot-tutorial/07-fitting/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "import mplhep\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-convertible",
   "metadata": {},
   "source": [
    "#### Definitions and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = 'data/'\n",
    "xs_corrections = { 'energy' : [88.4763 , 89.46658, 90.21986, 91.2291,  91.96428, 92.96229, 93.71362] ,\n",
    "                      'hadronic' : [2.0, 4.3, 7.7, 10.8, 4.7, -0.2, -1.6],\n",
    "                      'leptonic' : [0.09, 0.20, 0.36, 0.52, 0.22, -0.01, -0.08]}\n",
    "\n",
    "s_selection = np.load(path_data+'s_selection.npy')\n",
    "\n",
    "### These are the cuts determined in exercise 1 and 2 with the simulated data.\n",
    "\n",
    "cuts = {'ee_s' : {'Pcharged':(0,200), 'Ncharged':(0,7),'E_ecal':(65,200),'E_hcal':(0,5),'cos_thet': (-0.9,s_selection[0])}, \n",
    "         'mm' : {'Pcharged':(75,200), 'Ncharged':(1,7),'E_ecal':(0,27),'E_hcal':(0,40)}, \n",
    "         'qq' : {'Pcharged':(0,200), 'Ncharged':(7,200),'E_ecal':(27,90),'E_hcal':(0,100)},\n",
    "         'tt' : {'Pcharged':(0,75), 'Ncharged':(2,7),'E_ecal':(0,65),'E_hcal':(0,50)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if x is element of interval I\n",
    "def isin(x,I):\n",
    "    if x >= I[0] and x < I[1]: return True\n",
    "    else: return False\n",
    "\n",
    "# For calculation of sigma interval (explanation in report)   \n",
    "def t_test(x, sx, y, sy = 0):\n",
    "    return np.abs(x - y)/np.sqrt(sx**2 + sy**2)\n",
    "\n",
    "# categorize the events: put array indices of measured data into the corresponding energy category\n",
    "# return dictionary with indices\n",
    "def cat_energy(E_Lep,en_edges):\n",
    "    energy_indices={'energy_1':[] ,'energy_2':[] ,'energy_3':[] ,'energy_4':[] ,'energy_5':[] , 'energy_6':[],\n",
    "                    'energy_7':[]}\n",
    "    \n",
    "    i=0;\n",
    "    for e in 2*E_Lep:\n",
    "        if e<en_edges[1]:\n",
    "            energy_indices['energy_1'].append(i)\n",
    "        elif e>=en_edges[1] and e<en_edges[2]:\n",
    "            energy_indices['energy_2'].append(i)\n",
    "        elif e>=en_edges[2] and e<en_edges[3]:\n",
    "            energy_indices['energy_3'].append(i)\n",
    "        elif e>=en_edges[3] and e<en_edges[4]:\n",
    "            energy_indices['energy_4'].append(i)\n",
    "        elif e>=en_edges[4] and e<en_edges[5]:\n",
    "            energy_indices['energy_5'].append(i)\n",
    "        elif e>=en_edges[5] and e<en_edges[6]:\n",
    "            energy_indices['energy_6'].append(i)\n",
    "        elif e>=en_edges[6]:\n",
    "            energy_indices['energy_7'].append(i)\n",
    "        i+=1;\n",
    "    \n",
    "    return energy_indices\n",
    "\n",
    "# categorize for each energy category the events, after the decay channel. The cuts are applied\n",
    "def count_events(en_indices,cuts,Pchar,Nchar,E_ecal,E_hcal,cos_thet):\n",
    "    event_counter = {'energy_1':{'ee_s' : 0,'mm' : 0,'qq' : 0,'tt' : 0},\n",
    "                     'energy_2':{'ee_s' : 0,'mm' : 0,'qq' : 0,'tt' : 0},\n",
    "                     'energy_3':{'ee_s' : 0,'mm' : 0,'qq' : 0,'tt' : 0},\n",
    "                     'energy_4':{'ee_s' : 0,'mm' : 0,'qq' : 0,'tt' : 0},\n",
    "                     'energy_5':{'ee_s' : 0,'mm' : 0,'qq' : 0,'tt' : 0},\n",
    "                     'energy_6':{'ee_s' : 0,'mm' : 0,'qq' : 0,'tt' : 0},\n",
    "                     'energy_7':{'ee_s' : 0,'mm' : 0,'qq' : 0,'tt' : 0}}\n",
    "    \n",
    "    measurements = {'Pcharged': Pchar, 'Ncharged': Nchar,'E_ecal': E_ecal,'E_hcal': E_hcal, 'cos_thet': cos_thet}\n",
    "    \n",
    "    for energy, indices in en_indices.items():\n",
    "        \n",
    "        for i in indices:\n",
    "            for ch in cuts.keys():\n",
    "                is_channel = True;\n",
    "                for var, interval in cuts[ch].items():\n",
    "                    if not isin(measurements[var][i],interval):\n",
    "                        is_channel = False;\n",
    "                if is_channel:\n",
    "                    event_counter[energy][ch] += 1 \n",
    "                    continue;\n",
    "   \n",
    "    \n",
    "    return event_counter \n",
    "\n",
    "# get cos(theta) for muons from the data for exercise 4\n",
    "\n",
    "def get_cos_theta_muon(en_indices,cuts,Pchar,Nchar,E_ecal,E_hcal,cos_thet):\n",
    "    cos_theta_muon={'energy_1':[] ,'energy_2':[] ,'energy_3':[] ,'energy_4':[] ,'energy_5':[] , 'energy_6':[],\n",
    "                    'energy_7':[]}\n",
    "    \n",
    "    measurements = {'Pcharged': Pchar, 'Ncharged': Nchar,'E_ecal': E_ecal,'E_hcal': E_hcal, 'cos_thet': cos_thet}\n",
    "    for energy, indices in en_indices.items():\n",
    "        for i in indices:\n",
    "            for var, interval in cuts['mm'].items():\n",
    "                is_channel = True;\n",
    "                if not isin(measurements[var][i],interval):\n",
    "                    is_channel = False;\n",
    "                if is_channel:\n",
    "                    cos_theta_muon[energy].append(measurements[cos_theta][i])\n",
    "                    \n",
    "    \n",
    "    cos_theta_muon_np = np.array([cos_theta_muon['energy_1'],cos_theta_muon['energy_2'],cos_theta_muon['energy_3'],\n",
    "                                  cos_theta_muon['energy_4'],cos_theta_muon['energy_5'],cos_theta_muon['energy_6'],\n",
    "                                  cos_theta_muon['energy_7']])\n",
    "    \n",
    "    return cos_theta_muon_np\n",
    "    \n",
    "\n",
    "# # categorize for each energy category the events, after the decay channel. The cuts are applied\n",
    "# def count_events(en_indices,cuts,Pchar,Nchar,E_ecal,E_hcal,cos_thet):\n",
    "#     event_counter = {'energy_1':{'ee_s' : 0,'mm' : 0,'qq' : 0,'tt' : 0},\n",
    "#                      'energy_2':{'ee_s' : 0,'mm' : 0,'qq' : 0,'tt' : 0},\n",
    "#                      'energy_3':{'ee_s' : 0,'mm' : 0,'qq' : 0,'tt' : 0},\n",
    "#                      'energy_4':{'ee_s' : 0,'mm' : 0,'qq' : 0,'tt' : 0},\n",
    "#                      'energy_5':{'ee_s' : 0,'mm' : 0,'qq' : 0,'tt' : 0},\n",
    "#                      'energy_6':{'ee_s' : 0,'mm' : 0,'qq' : 0,'tt' : 0},\n",
    "#                      'energy_7':{'ee_s' : 0,'mm' : 0,'qq' : 0,'tt' : 0}}\n",
    "    \n",
    "#     for energy, indices in en_indices.items():\n",
    "#         for i in indices:\n",
    "#             if Nchar[i] > 7:\n",
    "#                 event_counter[energy]['qq'] += 1;\n",
    "#             elif E_ecal[i] > 70:\n",
    "#                 if -0.9<= cos_thet[i] and cos_thet[i]< s_selection[0]: event_counter[energy]['ee_s'] += 1;\n",
    "#             elif Pchar[i]>65:\n",
    "#                 event_counter[energy]['mm']+=1;\n",
    "#             else:\n",
    "#                 event_counter[energy]['tt']+=1;\n",
    "#     return event_counter \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-progress",
   "metadata": {},
   "source": [
    "#### Read in the OPAL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "with open(path_data+'daten_3.csv','r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    for row in csvreader:\n",
    "        rows.append(row)\n",
    "mean_energy_opal=np.array(list(zip(*rows[1:]))[0], dtype=float)\n",
    "lumi=np.array(list(zip(*rows[1:]))[1], dtype=float)\n",
    "stat=np.array(list(zip(*rows[1:]))[2], dtype=float)\n",
    "sys=np.array(list(zip(*rows[1:]))[3], dtype=float)\n",
    "sq_sum=np.array(list(zip(*rows[1:]))[4], dtype=float)\n",
    "\n",
    "lum_data = {'energy_1': {'lumi': lumi[0] ,'stat': stat[0] , 'sys': sys[0],'all': sq_sum[0]},\n",
    "            'energy_2': {'lumi': lumi[1] ,'stat': stat[1] , 'sys': sys[1],'all': sq_sum[1]},\n",
    "            'energy_3': {'lumi': lumi[2] ,'stat': stat[2] , 'sys': sys[2],'all': sq_sum[2]},\n",
    "            'energy_4': {'lumi': lumi[3] ,'stat': stat[3] , 'sys': sys[3],'all': sq_sum[3]},\n",
    "            'energy_5': {'lumi': lumi[4] ,'stat': stat[4] , 'sys': sys[4],'all': sq_sum[4]},\n",
    "            'energy_6': {'lumi': lumi[5] ,'stat': stat[5] , 'sys': sys[5],'all': sq_sum[5]},\n",
    "            'energy_7': {'lumi': lumi[6] ,'stat': stat[6] , 'sys': sys[6],'all': sq_sum[6]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Open the file introducing file path\n",
    "opal_data = uproot.open(path_data+'daten_3.root')\n",
    "ttree_name = 'myTTree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load branches\n",
    "branches_opal = opal_data[ttree_name].arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "### These are arrays of same length\n",
    "Nchar = ak.to_numpy(branches_opal['Ncharged'])\n",
    "Pchar = ak.to_numpy(branches_opal['Pcharged'])\n",
    "E_Ecal = ak.to_numpy(branches_opal['E_ecal'])\n",
    "E_Hcal = ak.to_numpy(branches_opal['E_hcal'])\n",
    "E_Lep = ak.to_numpy(branches_opal['E_lep'])\n",
    "cos_thet = ak.to_numpy(branches_opal['cos_thet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-burner",
   "metadata": {},
   "source": [
    "#### Event selection\n",
    "The data contains events, corresponding to different energies. For a propper calculation of cross sections, those events are categorized to the energies mentioned in the csv_file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_edges=[min(2*E_Lep)]\n",
    "for i in range(6):\n",
    "    en_edges.append((mean_energy_opal[i]+mean_energy_opal[i+1])/2)\n",
    "    \n",
    "en_edges.append(max(2*E_Lep))\n",
    "\n",
    "# print(en_edges)\n",
    "plt.style.use(mplhep.style.ATLAS) # load ATLAS plot style\n",
    "plt.title(r'LEP center of mass energy (=$\\sqrt{s}$)')\n",
    "hbins, hedges, _ = plt.hist(2*E_Lep,bins= en_edges,label=r'OPAL measurements')\n",
    "\n",
    "plt.xlim(88,94)\n",
    "plt.xlabel(r'$\\sqrt{s}$ $[GeV]$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply the event selection functions defined above\n",
    "energy_indices = cat_energy(E_Lep,en_edges)\n",
    "# Test of means of our categorizations fits the mean energy given in the csv file:\n",
    "\n",
    "energy_means = []\n",
    "energy_sigma = []\n",
    "\n",
    "for energy, indices in energy_indices.items():\n",
    "    e_mean = 0\n",
    "    e_sigma=0\n",
    "    for i in indices:\n",
    "        e_mean += 2*E_Lep[i]\n",
    "    e_mean = e_mean / len(indices)\n",
    "    for i in indices:\n",
    "        e_sigma += (2*E_Lep[i] - e_mean)**2\n",
    "    e_sigma = np.sqrt(e_sigma/ len(indices))\n",
    "    energy_means.append(e_mean)\n",
    "    energy_sigma.append(e_sigma)\n",
    "    \n",
    "\n",
    "energy_means = np.array(energy_means)\n",
    "energy_sigma = np.array(energy_sigma)\n",
    "\n",
    "# print(np.linalg.norm(energy_means-mean_energy_opal))\n",
    "# print(energy_sigma)\n",
    "# The error on the energy is to small to play any role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_counter = count_events(energy_indices,cuts,Pchar,Nchar,E_Ecal,E_Hcal,cos_thet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test if the event categorization worked\n",
    "counter=0;\n",
    "for energy, indices in energy_indices.items():\n",
    "    counter+=len(indices)\n",
    "    \n",
    "### Test if the energy categorization worked    \n",
    "counter1=0;\n",
    "for energy, index_lists in event_counter.items():\n",
    "    for channel, count in index_lists.items():\n",
    "        counter1 += count;\n",
    "\n",
    "print(len(E_Lep))\n",
    "print(counter)\n",
    "print(counter1) # counter1<total number of events ?? Backround ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-straight",
   "metadata": {},
   "source": [
    "#### Calculation of the cross sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in efficiency matrix, error matrix and thei inverses (from  Exercise 1)\n",
    "efficiency_matrix = np.load(path_data+'efficiency_matrix.npy')\n",
    "error_matrix = np.load(path_data+'error_matrix.npy')\n",
    "inv_efficiency_matrix = np.load(path_data+'inv_efficiency_matrix.npy')\n",
    "inv_error_matrix = np.load(path_data+'inv_error_matrix.npy')\n",
    "s_correction_factor = np.array([1/s_selection[1],1,1,1])\n",
    "s_correction_error = np.array([s_selection[2]/s_selection[1]**2,0,0,0])\n",
    "# print(s_correction_factor)\n",
    "# print(s_correction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the total cross sections for each energy level\n",
    "sigma = {'energy_1': np.zeros(4),'energy_2': np.zeros(4),'energy_3': np.zeros(4),'energy_4': np.zeros(4),\n",
    "         'energy_5': np.zeros(4),'energy_6': np.zeros(4),'energy_7': np.zeros(4)}\n",
    "\n",
    "d_sigma_stat = {'energy_1': np.zeros(4),'energy_2': np.zeros(4),'energy_3': np.zeros(4),'energy_4': np.zeros(4),\n",
    "                'energy_5': np.zeros(4),'energy_6': np.zeros(4),'energy_7': np.zeros(4)}\n",
    "\n",
    "d_sigma_sys = {'energy_1': np.zeros(4),'energy_2': np.zeros(4),'energy_3': np.zeros(4),'energy_4': np.zeros(4),\n",
    "               'energy_5': np.zeros(4),'energy_6': np.zeros(4),'energy_7': np.zeros(4)}\n",
    "\n",
    "energy_el= {'energy_1': 0, 'energy_2': 1, 'energy_3': 2, 'energy_4': 3, 'energy_5': 4, 'energy_6': 5, 'energy_7': 6}\n",
    "\n",
    "\n",
    "for energy, counters in event_counter.items():\n",
    "    counter_array = np.zeros(4);\n",
    "    \n",
    "    el={'ee_s': 0,'mm':1,'qq':2,'tt':3}\n",
    "    sigma_corr = np.array([xs_corrections['leptonic'][energy_el[energy]],xs_corrections['leptonic'][energy_el[energy]],\n",
    "                           xs_corrections['hadronic'][energy_el[energy]],xs_corrections['leptonic'][energy_el[energy]]])\n",
    "    for channel in counters:\n",
    "        counter_array[el[channel]]= event_counter[energy][channel]\n",
    "        \n",
    "    # Calculate cross section\n",
    "    sigma[energy] = np.dot(inv_efficiency_matrix,counter_array)*s_correction_factor/lum_data[energy]['lumi'] +sigma_corr\n",
    "    \n",
    "    # Calculate statistical error via propagation for cross section\n",
    "    d_sigma_stat[energy] = np.sqrt((np.dot(inv_error_matrix**2,counter_array**2)*s_correction_factor**2/lum_data[energy]['lumi']**2)\n",
    "                             +(np.dot(inv_efficiency_matrix**2,counter_array**2)*s_correction_error**2/lum_data[energy]['lumi']**2)\n",
    "                             +(np.dot(inv_efficiency_matrix**2,counter_array**2)*s_correction_factor**2*lum_data[energy]['stat']**2)\n",
    "                              *(1/lum_data[energy]['lumi'])**4)\n",
    "    \n",
    "    # Calculate systematical error via propagation for cross section\n",
    "    d_sigma_sys[energy] = (np.dot(inv_efficiency_matrix,counter_array)*s_correction_factor*lum_data[energy]['stat']\n",
    "                            *(1/lum_data[energy]['lumi'])**2)\n",
    "\n",
    "\n",
    "# Example for e+e- to e+e- at 88.4763 GeV\n",
    "print(f\"sigma = {sigma['energy_1'][0]} +/- {d_sigma_stat['energy_1'][0]} (stat) +/- {d_sigma_sys['energy_1'][0]} (sys)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-mainland",
   "metadata": {},
   "source": [
    "#### Plot the results. Breit-Wiger-Fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the results in numpy arrays, in order to make nice plots with matplotlip.pyplot\n",
    "\n",
    "sigma_arr = np.zeros((4,7))\n",
    "sigma_stat_arr = np.zeros((4,7))\n",
    "sigma_sys_arr = np.zeros((4,7))\n",
    "\n",
    "for energy in sigma.keys():\n",
    "    sigma_arr[0][energy_el[energy]] = sigma[energy][0]\n",
    "    sigma_arr[1][energy_el[energy]] = sigma[energy][1]\n",
    "    sigma_arr[2][energy_el[energy]] = sigma[energy][2]\n",
    "    sigma_arr[3][energy_el[energy]] = sigma[energy][3]\n",
    "    sigma_stat_arr[0][energy_el[energy]] = d_sigma_stat[energy][0]\n",
    "    sigma_stat_arr[1][energy_el[energy]] = d_sigma_stat[energy][1]\n",
    "    sigma_stat_arr[2][energy_el[energy]] = d_sigma_stat[energy][2]\n",
    "    sigma_stat_arr[3][energy_el[energy]] = d_sigma_stat[energy][3]\n",
    "    sigma_sys_arr[0][energy_el[energy]] = d_sigma_sys[energy][0]\n",
    "    sigma_sys_arr[1][energy_el[energy]] = d_sigma_sys[energy][1]\n",
    "    sigma_sys_arr[2][energy_el[energy]] = d_sigma_sys[energy][2]\n",
    "    sigma_sys_arr[3][energy_el[energy]] = d_sigma_sys[energy][3]   \n",
    "    \n",
    "d_sigma_arr = sigma_stat_arr + sigma_sys_arr\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 12),dpi=500)\n",
    "fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.4, hspace=0.4)\n",
    "plt.style.use(mplhep.style.ATLAS) # load ATLAS plot style\n",
    "def breit_wigner(sqrt_s,M,Gamma_ef,Gamma_Z):\n",
    "    s=sqrt_s**2\n",
    "    return 12*np.pi/M**2*(s*Gamma_ef)/((s-M**2)**2+(s**2*Gamma_Z**2/M**2))\n",
    "\n",
    "\n",
    "\n",
    "# Scale the errors by a factor of 10, in order to make them visible in the plot\n",
    "d_sigma_arr[0]= d_sigma_arr[0]*10\n",
    "d_sigma_arr[1]= d_sigma_arr[1]*10\n",
    "d_sigma_arr[2]= d_sigma_arr[2]*10\n",
    "d_sigma_arr[3]= d_sigma_arr[3]*10\n",
    "headers=[r'Cross-sections for $Z^0\\to e^+e^-$',r'Cross-sections for $Z^0\\to \\mu^+\\mu^-$',\n",
    "       r'Cross-sections for $Z^0\\to qq$',r'Cross-sections for $Z^0\\to \\tau^+\\tau^-$']\n",
    "# Generate errorbar plot of the results for the cross section\n",
    "\n",
    "M_Z=[]\n",
    "M_Z_sigma=[]\n",
    "Gamma_ef = []\n",
    "Gamma_ef_sigma = []\n",
    "Gamma_Z = []\n",
    "Gamma_Z_sigma = []\n",
    "sigma_max = []\n",
    "sigma_max_sigma = []\n",
    "\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(221+i)\n",
    "    ax.set_title(headers[i], fontsize=20)\n",
    "    ax.errorbar(energy_means, sigma_arr[i], d_sigma_arr[i],marker='.',linestyle='None',label=r'Measurements',markersize=10,capsize=3, capthick=1)\n",
    "    \n",
    "    coeffs, cov = curve_fit(breit_wigner, energy_means, sigma_arr[i],sigma=d_sigma_arr[i], \n",
    "                            absolute_sigma=True,p0=[91.1,240*240,2.5])\n",
    "    x=np.linspace(83, 95, 1000)\n",
    "    ax.plot(x,breit_wigner(x,*coeffs),label=r'Breit-Wigner-fit')\n",
    "    ax.set_xlim(83,95)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.set_xlabel(r'$\\sqrt{s}$ [GeV]')\n",
    "    ax.set_ylabel(r'$\\sigma$ [nb]')\n",
    "    ax.legend() \n",
    "    \n",
    "    \n",
    "    # these are matplotlib.patch.Patch properties\n",
    "    textstr = '\\n'.join((\n",
    "    r'$M_Z=(%.2f \\pm %.2f) $ GeV' % (np.abs(coeffs[0]),np.sqrt(cov[0][0]), ),\n",
    "    r'$\\Gamma_e \\Gamma_f=(%.2f \\pm %.2f)$ GeV$^4\\mu$b' % (coeffs[1]/1000,np.sqrt(cov[1][1])/1000, ),\n",
    "    r'$\\Gamma_Z=(%.2f \\pm %.2f) $ GeV ' % (coeffs[2],np.sqrt(cov[2][2]), )))\n",
    "\n",
    "    # these are matplotlib.patch.Patch properties\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax.text(0.067, 0.75, textstr, transform=ax.transAxes, fontsize=14,\n",
    "        verticalalignment='top', bbox=props)\n",
    "    \n",
    "    M_Z.append(coeffs[0])\n",
    "    M_Z_sigma.append(np.sqrt(cov[0][0]))\n",
    "    Gamma_ef.append(coeffs[1])\n",
    "    Gamma_ef_sigma.append(np.sqrt(cov[1][1]))\n",
    "    Gamma_Z.append(coeffs[2])\n",
    "    Gamma_Z_sigma.append(np.sqrt(cov[2][2]))\n",
    "    sigma_max.append(breit_wigner(coeffs[0], *coeffs))\n",
    "    sigma_max_sigma.append(12*np.pi*np.sqrt(cov[1][1]/(coeffs[0]**2*coeffs[2]**2)**2\n",
    "                                +4*coeffs[1]**2*cov[0][0]/(coeffs[0]**3*coeffs[2]**2)**2\n",
    "                                               +4*coeffs[1]**2*cov[2][2]/(coeffs[0]**2*coeffs[2]**3)**2))\n",
    "       \n",
    "plt.show()\n",
    "\n",
    "nb_to_GeV = 10.0**(-37)*1/(1.973*10**(-16))**2 \n",
    "\n",
    "M_Z=np.array(M_Z)\n",
    "M_Z_sigma=np.array(M_Z_sigma)\n",
    "Gamma_ef = np.array(Gamma_ef)*nb_to_GeV\n",
    "Gamma_ef_sigma = np.array(Gamma_ef_sigma)*nb_to_GeV\n",
    "Gamma_Z = np.array(Gamma_Z)\n",
    "Gamma_Z_sigma = np.array(Gamma_Z_sigma)\n",
    "sigma_max = np.array(sigma_max)\n",
    "sigma_max_sigma = np.array(sigma_max_sigma)\n",
    "\n",
    "# weighted (by max) mean of M_Z over the decay channels\n",
    "M_Z_ws=np.sum(M_Z*sigma_max)/np.sum(sigma_max)\n",
    "M_Z_ws_sigma=np.sqrt((np.sum(M_Z_sigma**2*sigma_max**2)+np.sum(M_Z**2*sigma_max_sigma**2))/np.sum(sigma_max)**4)\n",
    "\n",
    "\n",
    "# weighted (by max) mean of Gamma_Z over the decay channels\n",
    "\n",
    "Gamma_Z_ws=np.sum(Gamma_Z*sigma_max)/np.sum(sigma_max)\n",
    "Gamma_Z_ws_sigma=np.sqrt((np.sum(Gamma_Z_sigma**2*sigma_max**2)+np.sum(Gamma_Z**2*sigma_max_sigma**2))/np.sum(sigma_max)**4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-ranch",
   "metadata": {},
   "source": [
    "#### Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Z-Boson properties:\")\n",
    "print(f\"-------------------------------------------------------------------------------------------------\")\n",
    "M_z_lit = [91.1876,0.0021] #[PDG]\n",
    "Gamma_z_lit = [2.4952,0.002]\n",
    "print(f\"M_Z_lit=(%.3f \\pm %.3f) GeV\" % (M_z_lit[0],M_z_lit[1]))\n",
    "print(f\"M_Z=(%.3f \\pm %.3f) GeV, t-Test = %3f\" % (M_Z_ws,M_Z_ws_sigma,t_test(M_Z_ws,M_Z_ws_sigma,*M_z_lit)))\n",
    "print(f\"Gamma_Z_lit=(%.3f \\pm %.3f) GeV\" % (Gamma_z_lit[0],Gamma_z_lit[1]))\n",
    "print(f\"Gamma_Z=(%.3f \\pm %.3f) GeV, t-Test = %3f\" % (Gamma_Z_ws,Gamma_Z_ws_sigma,t_test(Gamma_Z_ws,Gamma_Z_ws_sigma,*Gamma_z_lit)))\n",
    "print(f\"-------------------------------------------------------------------------------------------------\")\n",
    "print(f\"\\n\")\n",
    "\n",
    "Gamma_e = np.sqrt(Gamma_ef[0])\n",
    "Gamma_e_sigma = (1/2 * Gamma_ef_sigma[0]/np.sqrt(Gamma_ef[0]))\n",
    "\n",
    "p_Gamma =[Gamma_e]\n",
    "p_Gamma_sigma = [Gamma_e_sigma]\n",
    "\n",
    "for i in [1,2,3]:\n",
    "    p_Gamma.append(Gamma_ef[i]/Gamma_e)\n",
    "    p_Gamma_sigma.append(np.sqrt((Gamma_ef_sigma[i]/Gamma_e)**2+(Gamma_ef[i]/Gamma_e**2 * Gamma_e_sigma)**2))\n",
    "    \n",
    "p_Gamma =np.array(p_Gamma)\n",
    "p_Gamma_sigma = np.array(p_Gamma_sigma)\n",
    "\n",
    "\n",
    "    \n",
    "print(f\"Partial Decay widths:\")\n",
    "print(f\"-------------------------------------------------------------------------------------------------\")\n",
    "Gamma_lep_lit = 83.8/1000\n",
    "Gamma_qq_lit=2*0.299+3*0.378\n",
    "print(f\"Gamma_lep_lit=%.3f MeV\" % (Gamma_lep_lit*1000))\n",
    "print(f\"Gamma_qq_lit=%.3f GeV\" % (Gamma_qq_lit))\n",
    "print(f\"Gamma_e=(%.3f \\pm %.3f) MeV, t-Test = %3f\" % (Gamma_e*1000,Gamma_e_sigma*1000,t_test(Gamma_e,Gamma_e_sigma,Gamma_lep_lit)))\n",
    "print(f\"Gamma_q=(%.3f \\pm %.3f) GeV, t-Test = %3f\" % (p_Gamma[1]*1000,p_Gamma_sigma[1]*1000,t_test(p_Gamma[1],p_Gamma_sigma[1],Gamma_lep_lit)))\n",
    "print(f\"Gamma_mu=(%.3f \\pm %.3f) MeV, t-Test = %3f\" % (p_Gamma[2],p_Gamma_sigma[2],t_test(p_Gamma[2],p_Gamma_sigma[2],Gamma_qq_lit)))\n",
    "print(f\"Gamma_tau=(%.3f \\pm %.3f) MeV, t-Test = %3f\" % (p_Gamma[3]*1000,p_Gamma_sigma[3]*1000,t_test(p_Gamma[3],p_Gamma_sigma[3],Gamma_lep_lit)))\n",
    "print(f\"-------------------------------------------------------------------------------------------------\")\n",
    "print(f\"\\n\")\n",
    "print(f\"Calculation of the number of neutrino generations\")\n",
    "print(f\"-------------------------------------------------------------------------------------------------\")\n",
    "gamma_nu = 0.1676 ## Necessary assumption (this is correct!)\n",
    "Gamma_nu_ges = Gamma_Z_ws-np.sum(p_Gamma)\n",
    "Gamma_nu_ges_sigma = np.sqrt(Gamma_Z_ws_sigma**2+np.sum(p_Gamma_sigma**2))\n",
    "number_nu = Gamma_nu_ges / gamma_nu\n",
    "number_nu_sigma = number_nu *Gamma_nu_ges_sigma\n",
    "print(f\"Number of neutrino generations=(%.3f \\pm %.3f)\" % (number_nu,number_nu_sigma))\n",
    "print(f\"-------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-spoke",
   "metadata": {},
   "source": [
    "# Exercise 5: Tests on lepton universality¶\n",
    "\n",
    "* Test the lepton universality from the total cross sectinos on the peak for $Z\\to e^+ e^-$, $Z\\to \\mu^+ \\mu^-$ and $Z\\to \\tau^+ \\tau^-$ events. What is the ratio of the total cross section of the hadronic channel to the leptonic channels on the peak? Compare with the ratios obtained from the branching rations and discuss possible differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_ratio=sigma_max/sigma_max[2]\n",
    "sigma_ratio_sigma=np.sqrt((sigma_max_sigma/sigma_max[2])**2+(sigma_max/sigma_max[2]**2*sigma_max_sigma[2])**2)\n",
    "print(f\"ratio of the total cross section of the hadronic channel to the leptonic channels on the peak\")\n",
    "print(f\"-------------------------------------------------------------------------------------------------\")\n",
    "print('sigma_max_ee/sigma_max_qq: (%.3f +/- %.3f)'%(sigma_ratio[0], sigma_ratio_sigma[0]))\n",
    "print('sigma_max_mm/sigma_max_qq: (%.3f +/- %.3f)'%(sigma_ratio[1], sigma_ratio_sigma[1]))\n",
    "print('sigma_max_tt/sigma_max_qq: (%.3f +/- %.3f)'%(sigma_ratio[3], sigma_ratio_sigma[3]))\n",
    "print(f\"-------------------------------------------------------------------------------------------------\")\n",
    "print(f\"\\n\")\n",
    "branch_ratio=p_Gamma/Gamma_Z_ws\n",
    "branch_ratio_sigma=np.sqrt((p_Gamma_sigma/Gamma_Z_ws)**2+(Gamma_Z_ws_sigma*np.array(p_Gamma)/Gamma_Z_ws**2)**2)\n",
    "ratio_ratio=branch_ratio/branch_ratio[2]\n",
    "ratio_ratio_sigma=np.sqrt((branch_ratio_sigma/branch_ratio[2])**2+(branch_ratio_sigma[2]*branch_ratio/branch_ratio[2]**2)**2)\n",
    "print('branching ratios:')\n",
    "print(f\"-------------------------------------------------------------------------------------------------\")\n",
    "print('Gamma_e/Gamma_z: (%.3f +/- %.3f) '%(branch_ratio[0], branch_ratio_sigma[0]))\n",
    "print('Gamma_m/Gamma_z: (%.3f +/- %.3f) '%(branch_ratio[1], branch_ratio_sigma[1]))\n",
    "print('Gamma_q/Gamma_z:  (%.3f +/- %.3f) '%(branch_ratio[2], branch_ratio_sigma[2]))\n",
    "print('Gamma_t/Gamma_z:  (%.3f +/- %.3f)'%(branch_ratio[3], branch_ratio_sigma[3]))\n",
    "print(f\"-------------------------------------------------------------------------------------------------\")\n",
    "print(f\"\\n\")\n",
    "print(f\"Test of lepton universality\")\n",
    "print(f\"-------------------------------------------------------------------------------------------------\")\n",
    "print('ratio e/q: (%.3f +/- %.3f) '%(ratio_ratio[0], ratio_ratio_sigma[0]))\n",
    "print('ratio m/q: (%.3f +/- %.3f) '%(ratio_ratio[1], ratio_ratio_sigma[1]))\n",
    "print('ratio t/q: (%.3f +/- %.3f)'%(ratio_ratio[3], ratio_ratio_sigma[3]))\n",
    "print(f\"-------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-nurse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
