{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beautiful-worst",
   "metadata": {},
   "source": [
    "# Exercise 1: Optimize lepton selection\n",
    "\n",
    "* First, print the distributions of the relevant variables for *all* the Monte Carlo samples (i.e. all the *channels* of the $Z$-boson decay to be studied). Which variables are these? Give sensible ranges to include all the events in the samples (both MC and OPAL data) \n",
    "* Do the same for **one** of the OPAL data samples (your lab assistant will decide which one you choose).\n",
    "* Describe the results.\n",
    "* Optimize the object selection by applying cuts. Make a strategy on how to proceed to find the optimal selection. which information do you need?\n",
    "* Determine the efficiency and the amount of background for each $Z$ decay channel. Use the simulated events $e^+e^-$, $\\mu^+\\mu^-$, $\\tau^+\\tau^-$ and hadrons ($qq$). Represent the result in a matrix form and think carefully about how you have to correct the measured rates. Don't forget to calculate the errors!\n",
    "* How do we estimate the statistical fluctuations per bin?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-memory",
   "metadata": {},
   "source": [
    "#### Import libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "import mplhep\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_efficiency_matrix(data,cuts,relevant_vars):\n",
    "    efficiency_matrix = np.zeros((4,4))\n",
    "    error_matrix = np.zeros((4,4))\n",
    "\n",
    "    el={'ee': 0,'mm':1,'qq':2,'tt':3}\n",
    "    \n",
    "    ### Calculate the efficiency matrix elements and errors\n",
    "    # store the errors in an extra matrix\n",
    "     \n",
    "    # How are the efficiency matrix and the corresponding error calculated?\n",
    "    # For each selection (z0 -> {ee,mm,qq,tt}) there are known cuts (from looking at te MC data)\n",
    "    # the calculated efficiency of the distinction between two channels from above (labeled with i and j) will be stored in the (i,j) component of the efficiency matrix eps_(i,j)\n",
    "    # In relevant_vars the variables, which are needed for a proper distinction (selected by looking at MC data) are stored for each pair of possible channels\n",
    "    # The cuts (stored in cuts) are applied to the relevant variables (by masking the awkward arrays)\n",
    "    # The (estimator of) efficiency is than calculated by\n",
    "    #                                                        eps = passed (=: k) / total (=:N)\n",
    "    # How to calculate the errors ?\n",
    "    # The (estimated) efficiency is the probability of succes with a certain selection. \n",
    "    # For succes failure experiments it is known, that the probability to get k times succes out of N trials is\n",
    "    # \n",
    "    #               P(k;N,eps) = binom(N,k) * eps^k *(1-eps)^(N-k)    \n",
    "    #\n",
    "    # k is a possible value of a probability variable X which counts the succes times X = sum_{i=1,...,N} Y (distribution of Y = Bernoulli)\n",
    "    #\n",
    "    # The maximum likelihood estimator (MLE) is eps = X / N = k / N\n",
    "    # The variance is V(eps) = V(X/N) = 1/N^2 sum(V(X)) = 1/N^2 V(sum_{i=1,...,N} Y) = 1/ N V(Y) = 1/N eps(1-eps)\n",
    "    # Summary: eps = k/N, sigma_eps^2 = 1/N eps(1-eps) -> sigma_eps = sqrt(1/N eps(1-eps))\n",
    "    \n",
    "    # However this methods results in absurd limiting cases: for eps = 0,1 the error is 0. This is unphysical\n",
    "    # A correct treatment of the errors is supplied in https://arxiv.org/abs/physics/0701199. We use their results directly in the code below:\n",
    "    \n",
    "    for channel_i,cuts_i in cuts.items():\n",
    "        for channel_j,rel_vars in relevant_vars[channel_i].items():\n",
    "            passed = 0\n",
    "            total = 0\n",
    "            for var in rel_vars:\n",
    "                mask0 = data[channel_j][var]>= cuts_i[var][0]\n",
    "                mask1 = data[channel_j][var] < cuts_i[var][1]\n",
    "                total +=len(mask0)\n",
    "                passed += sum(mask0)+sum(mask1)-len(mask0)\n",
    "            eps = (passed+1)/(total+2)\n",
    "            efficiency_matrix[el[channel_i]][el[channel_j]]=eps\n",
    "            error_matrix[el[channel_i]][el[channel_j]] = np.sqrt(eps * (passed+2)/(total+3) - eps**2)\n",
    "\n",
    "\n",
    "    return efficiency_matrix,error_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-broadcasting",
   "metadata": {},
   "source": [
    "#### Load the relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specify the folder path for MC samples\n",
    "path_data = 'data/'\n",
    "\n",
    "### Open the file introducing file path\n",
    "mc_data_ee = uproot.open(path_data+'ee.root')\n",
    "mc_data_mm = uproot.open(path_data+'mm.root')\n",
    "mc_data_qq = uproot.open(path_data+'qq.root')\n",
    "mc_data_tt = uproot.open(path_data+'tt.root')\n",
    "ttree_name = 'myTTree'\n",
    "\n",
    "### Print list of 'branches' of the TTree (i.e. list of variable names)\n",
    "# print(mc_data_ee[ttree_name].keys())\n",
    "\n",
    "### Load branches\n",
    "branches_ee = mc_data_ee[ttree_name].arrays()\n",
    "branches_mm = mc_data_mm[ttree_name].arrays()\n",
    "branches_qq = mc_data_qq[ttree_name].arrays()\n",
    "branches_tt = mc_data_tt[ttree_name].arrays()\n",
    "\n",
    "\n",
    "### List of variables (of interest)\n",
    "variables=['Pcharged', 'Ncharged', 'E_ecal', 'E_hcal']\n",
    "channels=['ee','mm','qq','tt'] \n",
    "\n",
    "# print(channels)\n",
    "# print(len(channels))\n",
    "\n",
    "### For later purposes (to calculate efficiency matrix) we store the data from braches into a list\n",
    "mc_data = {'ee' : {}, 'mm' : {}, 'qq' : {}, 'tt' : {}}\n",
    "mc_data['ee'] = branches_ee\n",
    "mc_data['mm'] = branches_mm\n",
    "mc_data['qq'] = branches_qq\n",
    "mc_data['tt'] = branches_tt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Read in the variables for all MC data samples\n",
    "Pchar=ak.Array([branches_ee[variables[0]],branches_mm[variables[0]],branches_qq[variables[0]],branches_tt[variables[0]]])\n",
    "Nchar=ak.Array([branches_ee[variables[1]],branches_mm[variables[1]],branches_qq[variables[1]],branches_tt[variables[1]]])\n",
    "E_ecal=ak.Array([branches_ee[variables[2]],branches_mm[variables[2]],branches_qq[variables[2]],branches_tt[variables[2]]])\n",
    "E_hcal=ak.Array([branches_ee[variables[3]],branches_mm[variables[3]],branches_qq[variables[3]],branches_tt[variables[3]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-vacuum",
   "metadata": {},
   "source": [
    "#### Plot the MC data samples to nice looking histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[r'$Z^0$ $\\to$ $e^+e^-$',r'$Z^0$ $\\to$ $\\mu^+\\mu^-$',r'$Z^0$ $\\to$ hadrons',r'$Z^0$ $\\to$ $\\tau^+\\tau^-$']\n",
    "plt.style.use(mplhep.style.ATLAS) # load ATLAS plot style\n",
    "plt.title(r'PCharged: total sum of charged momenta')\n",
    "for i in np.arange(4):\n",
    "    plt.hist(ak.to_numpy(Pchar[i]),bins=np.arange(0,120,0.1),label=labels[i],alpha=0.5)\n",
    "    \n",
    "plt.xlim(0,120)\n",
    "plt.ylim(0,2200)\n",
    "plt.xlabel(r'PCharged [Gev]')\n",
    "plt.legend()\n",
    "plt.savefig('pchar_hist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(r'NCharged: charged multiplicity')\n",
    "for i in np.arange(4):\n",
    "    plt.hist(ak.to_numpy(Nchar[i]),bins=np.arange(0,60,1),label=labels[i],alpha=0.5)\n",
    "\n",
    "plt.xlim(0,45)\n",
    "plt.ylim(0,100000)\n",
    "plt.xlabel(r'NCharged')\n",
    "plt.legend()\n",
    "plt.savefig('nchar_hist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(r'E_ECal: total energy in the ECal')\n",
    "for i in np.arange(4):\n",
    "    plt.hist(ak.to_numpy(E_ecal[i]),bins=np.arange(0,120,0.1),label=labels[i],alpha=0.5)\n",
    "\n",
    "plt.xlim(0,120)\n",
    "plt.ylim(0,5000)\n",
    "plt.xlabel(r'E_ECal [GeV]')\n",
    "plt.legend()\n",
    "plt.savefig('e_ecal_hist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(r'E_HCal: total energy in the HCal')\n",
    "for i in np.arange(4):\n",
    "    plt.hist(ak.to_numpy(E_hcal[i]),bins=np.arange(0,80,0.08),label=labels[i],alpha=0.5)\n",
    "\n",
    "plt.xlim(0,80)\n",
    "plt.ylim(0,3000)\n",
    "plt.xlabel(r'E_HCal [Gev]')\n",
    "plt.legend()\n",
    "plt.savefig('e_hcal_hist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-masters",
   "metadata": {},
   "source": [
    "#### Cut strategy\n",
    "We apply cuts to every variable of each channel (stored in cuts). To distinguish different decay channels of the Z0 boson, different variables are relevant for different distinctions (stored relevant_vars). With this information, the efficiency of event selection can be calculated. The results will be represented on a 4x4 \"efficiency matrx\".\n",
    "For explanation how the efficiency and the corresponding errors are calculated, see $\\texttt{functions.py}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts = {'ee' : {'Pcharged':(0,200), 'Ncharged':(0,7),'E_ecal':(65,200),'E_hcal':(0,5)}, \n",
    "         'mm' : {'Pcharged':(75,200), 'Ncharged':(1,7),'E_ecal':(0,27),'E_hcal':(0,40)}, \n",
    "         'qq' : {'Pcharged':(0,200), 'Ncharged':(7,200),'E_ecal':(27,90),'E_hcal':(0,100)},\n",
    "         'tt' : {'Pcharged':(0,75), 'Ncharged':(2,7),'E_ecal':(0,65),'E_hcal':(0,50)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_vars={'ee': {'ee':['Pcharged','Ncharged','E_ecal','E_hcal'],'mm':['E_ecal'],'qq': ['Ncharged'],'tt':['E_ecal']},\n",
    "               'mm': {'ee':['E_ecal'],'mm':['Pcharged','Ncharged','E_ecal','E_hcal'],'qq':['Ncharged'],'tt':['Pcharged']},\n",
    "               'qq': {'ee':['Ncharged'],'mm':['Ncharged'],'qq':['Pcharged','Ncharged','E_ecal','E_hcal'],'tt':['Ncharged']},\n",
    "               'tt': {'ee':['E_ecal'],'mm':['Pcharged'],'qq':['Ncharged'],'tt':['Pcharged','Ncharged','E_ecal','E_hcal']}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-shock",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "efficiency_matrix,error_matrix = get_efficiency_matrix(mc_data,cuts,relevant_vars)\n",
    "print(f\"efficiency matrx: \\n\", efficiency_matrix, \"\\n\")\n",
    "print(f\"error matrix: \\n\", error_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-accordance",
   "metadata": {},
   "source": [
    "### Matrix Inversion\n",
    "To determine the uncertainties of the matrix elements after the inversion we use Monte Carlo toy experiments. In this context, what are the advantages and disadvantages of this method when compared to analytical expressions? Discuss it briefly.\n",
    "\n",
    "**References**:\n",
    "* Propagation of Errors for Matrix Inversion: https://arxiv.org/abs/hep-ex/9909031v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Number of toy experiments to be done\n",
    "ntoy = 100000\n",
    "\n",
    "### Create numpy matrix of list to append elements of inverted toy matrices\n",
    "inverse_toys = np.empty((4,4))\n",
    "\n",
    "# Create toy efficiency matrix out of gaussian-distributed random values\n",
    "for i in range(0,ntoy,1):\n",
    "    toy_matrix = np.zeros((4,4))\n",
    "    #np.random.seed(2)\n",
    "    toy_matrix = np.random.normal(efficiency_matrix,error_matrix,size=(4,4))\n",
    "    \n",
    "    ### Invert toy matrix\n",
    "    inverse_toy = np.linalg.inv(toy_matrix)\n",
    "    \n",
    "    #print(inverse_toys.item(0,0),inverse_toy.item(0,0))\n",
    "    # Append values\n",
    "    \n",
    "    inverse_toys = np.dstack((inverse_toys,inverse_toy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gaussian function to fit to the toy distributions:\n",
    "def gauss(x, A, mu, sigma):\n",
    "    return A*np.exp(-(x-mu)**2/(2.*sigma**2))\n",
    "\n",
    "inverse_errors = np.zeros((4,4))\n",
    "inverse_means = np.zeros((4,4))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10),dpi=80)\n",
    "plt.style.use(mplhep.style.ATLAS) # load ATLAS plot style\n",
    "fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.2, hspace=0.2)\n",
    "ax00 = plt.subplot(4,4,1)\n",
    "ax01 = plt.subplot(4,4,2)\n",
    "ax02 = plt.subplot(4,4,3)\n",
    "ax03 = plt.subplot(4,4,4)\n",
    "\n",
    "ax10 = plt.subplot(4,4,5)\n",
    "ax11 = plt.subplot(4,4,6)\n",
    "ax12 = plt.subplot(4,4,7)\n",
    "ax13 = plt.subplot(4,4,8)\n",
    "\n",
    "ax20 = plt.subplot(4,4,9)\n",
    "ax21 = plt.subplot(4,4,10)\n",
    "ax22 = plt.subplot(4,4,11)\n",
    "ax23 = plt.subplot(4,4,12)\n",
    "\n",
    "ax30 = plt.subplot(4,4,13)\n",
    "ax31 = plt.subplot(4,4,14)\n",
    "ax32 = plt.subplot(4,4,15)\n",
    "ax33 = plt.subplot(4,4,16)\n",
    "\n",
    "axes = [[ax00,ax01,ax02,ax03],\n",
    "        [ax10,ax11,ax12,ax13],\n",
    "        [ax20,ax21,ax22,ax23],\n",
    "        [ax30,ax31,ax32,ax33]]\n",
    "\n",
    "\n",
    "# Fill histograms for each inverted matrix coefficient:\n",
    "for j in range(0,4,1):\n",
    "    for k in range(0,4,1):\n",
    "        \n",
    "        ## Guess initial parameters for the fit, use them for proper ranges of the histograms below\n",
    "        p0 = [ntoy/10.,np.mean(inverse_toys[j,k,:]),np.std(inverse_toys[j,k,:])]\n",
    "        \n",
    "        # Generate the histograms of the matrix elements of the toys\n",
    "        hbins, hedges, _ = axes[j][k].hist(inverse_toys[j,k,:],bins=np.linspace(p0[1]-4*p0[2],p0[1]+4*p0[2],200),\n",
    "                                           histtype='step', linewidth=2, label=f'toyhist{j}{k}')\n",
    "        \n",
    "\n",
    "\n",
    "        # Get the fitted curve\n",
    "        h_mid = 0.5*(hedges[1:] + hedges[:-1]) #Calculate midpoints for the fit\n",
    "        coeffs, _ = curve_fit(gauss, h_mid, hbins,p0, maxfev=1000)\n",
    "        h_fit = gauss(h_mid, *coeffs)\n",
    "        \n",
    "        axes[j][k].plot(h_mid, h_fit,label=f'Fit{j}{k}')\n",
    "        \n",
    "        axes[j][k].legend()\n",
    "        \n",
    "        \n",
    "\n",
    "        inverse_means[j,k] = coeffs[1]\n",
    "        inverse_errors[j,k] = abs(coeffs[2])\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "inv_efficiency_matrix = np.linalg.inv(efficiency_matrix)\n",
    "print(f\"Inverse efficiency matrix:\\n{inv_efficiency_matrix}\")\n",
    "print(f\"Erros for the inverse matrix:\\n{inverse_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_data+'efficiency_matrix',efficiency_matrix)\n",
    "np.save(path_data+'error_matrix',error_matrix)\n",
    "np.save(path_data+'inv_efficiency_matrix',inv_efficiency_matrix)\n",
    "np.save(path_data+'inv_error_matrix',inverse_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
